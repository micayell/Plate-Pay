from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from deepface import DeepFace
import numpy as np
from PIL import Image
import io
import base64
import os
import tempfile
from typing import Dict, List, Optional, Tuple
from pydantic import BaseModel
import asyncio

app = FastAPI(title="Face Recognition API", version="1.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic ëª¨ë¸ë“¤
class ImageToBase64Response(BaseModel):
    success: bool
    message: str
    base64_data: Optional[str] = None

class FaceCompareRequest(BaseModel):
    base64_text: str

class FaceCompareResponse(BaseModel):
    success: bool
    message: str
    is_same_person: bool
    confidence: Optional[float] = None


def extract_face_embedding(image_array: np.ndarray) -> Optional[np.ndarray]:
    """DeepFaceë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ"""
    try:
        print(f"ğŸ” ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ ì‹œì‘ - ì´ë¯¸ì§€ í¬ê¸°: {image_array.shape}")
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì´ë¯¸ì§€ ì €ì¥ (DeepFaceê°€ íŒŒì¼ ê²½ë¡œë¥¼ ìš”êµ¬í•¨)
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_file:
            # numpy arrayë¥¼ PIL Imageë¡œ ë³€í™˜ í›„ ì €ì¥
            if len(image_array.shape) == 3:
                image = Image.fromarray(image_array)
            else:
                image = Image.fromarray(image_array, mode='L')
            
            image.save(temp_file.name, 'JPEG')
            temp_path = temp_file.name
            print(f"ğŸ“ ì„ì‹œ ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥ë¨: {temp_path}")
        
        try:
            # DeepFaceë¡œ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ (VGG-Face ëª¨ë¸ ì‚¬ìš©)
            print("ğŸ¤– DeepFace VGG-Face ëª¨ë¸ë¡œ ì–¼êµ´ ë¶„ì„ ì¤‘...")
            embedding_result = DeepFace.represent(img_path=temp_path, model_name='VGG-Face', enforce_detection=True)
            print(f"âœ… ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ ì„±ê³µ!")
            
            # ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¼ ìˆ˜ ìˆìŒ
            if isinstance(embedding_result, list) and len(embedding_result) > 0:
                embedding = np.array(embedding_result[0]['embedding'])
                print(f"ğŸ“Š ì„ë² ë”© ë²¡í„° í¬ê¸°: {embedding.shape}, ë²”ìœ„: [{embedding.min():.4f}, {embedding.max():.4f}]")
            else:
                embedding = np.array(embedding_result['embedding'])
                print(f"ğŸ“Š ì„ë² ë”© ë²¡í„° í¬ê¸°: {embedding.shape}, ë²”ìœ„: [{embedding.min():.4f}, {embedding.max():.4f}]")
            
            return embedding
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(temp_path):
                os.unlink(temp_path)
                print(f"ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œë¨: {temp_path}")
    
    except ValueError as e:
        if "Face could not be detected" in str(e):
            print(f"âŒ ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨: ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"ğŸ’¡ í•´ê²° ë°©ë²•: ë” ëª…í™•í•œ ì–¼êµ´ ì‚¬ì§„ì„ ì‚¬ìš©í•˜ì„¸ìš” (ì •ë©´, ë°ì€ ì¡°ëª…)")
        else:
            print(f"âŒ ì–¼êµ´ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return None
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        print(f"ğŸ”§ ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        return None

def compare_faces_deepface(known_embedding: np.ndarray, test_embedding: np.ndarray, threshold: float = 0.6) -> Tuple[bool, float]:
    """ë‘ ì–¼êµ´ ì„ë² ë”© ë¹„êµ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì‚¬ìš©)"""
    try:
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        dot_product = np.dot(known_embedding, test_embedding)
        norm_a = np.linalg.norm(known_embedding)
        norm_b = np.linalg.norm(test_embedding)
        
        if norm_a == 0 or norm_b == 0:
            return False, 0.0
        
        cosine_similarity = dot_product / (norm_a * norm_b)
        
        # ì‹ ë¢°ë„ ê³„ì‚° (0-100%)
        confidence = max(0, cosine_similarity * 100)
        
        # ë§¤ì¹˜ ì—¬ë¶€ íŒë‹¨ (thresholdë³´ë‹¤ ë†’ìœ¼ë©´ ê°™ì€ ì‚¬ëŒ)
        is_match = cosine_similarity >= threshold
        
        return is_match, confidence
    
    except Exception as e:
        print(f"Error comparing faces: {str(e)}")
        return False, 0.0

async def process_uploaded_image(file: UploadFile) -> np.ndarray:
    """ì—…ë¡œë“œëœ ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬"""
    if not file.content_type or not file.content_type.startswith('image/'):
        raise HTTPException(status_code=400, detail="ì—…ë¡œë“œëœ íŒŒì¼ì´ ì´ë¯¸ì§€ê°€ ì•„ë‹™ë‹ˆë‹¤.")
    
    try:
        image_data = await file.read()
        image = Image.open(io.BytesIO(image_data))
        
        # RGBë¡œ ë³€í™˜
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        return np.array(image)
    
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.get("/")
async def root():
    return {"message": "Face Recognition API"}

@app.post("/api/v1/image/to-base64", response_model=ImageToBase64Response)
async def convert_image_to_base64(file: UploadFile = File(...)):
    """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜í•˜ëŠ” API"""

    print(f"\nğŸ“¸ ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜ ìš”ì²­ - íŒŒì¼: {file.filename}")

    try:
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        image_array = await process_uploaded_image(file)
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ - í¬ê¸°: {image_array.shape}")

        # ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ
        face_embedding = extract_face_embedding(image_array)

        if face_embedding is None:
            print(f"âŒ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨")
            return ImageToBase64Response(
                success=False,
                message="ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª…í™•í•œ ì–¼êµ´ ì‚¬ì§„ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
            )

        # NumPy ë°°ì—´ì„ base64ë¡œ ë³€í™˜
        base64_data = base64.b64encode(face_embedding.tobytes()).decode('utf-8')

        print(f"âœ… base64 ë³€í™˜ ì™„ë£Œ - ê¸¸ì´: {len(base64_data)} ë¬¸ì")

        return ImageToBase64Response(
            success=True,
            message="ì´ë¯¸ì§€ê°€ ì„±ê³µì ìœ¼ë¡œ base64ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.",
            base64_data=base64_data
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ë³€í™˜ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/api/v1/face/compare", response_model=FaceCompareResponse)
async def compare_face_with_base64(file: UploadFile = File(...), base64_text: str = Form(...)):
    """ì´ë¯¸ì§€ì™€ base64 í…ìŠ¤íŠ¸ë¥¼ ë¹„êµí•˜ì—¬ ë™ì¼ ì¸ë¬¼ì¸ì§€ í™•ì¸í•˜ëŠ” API"""

    print(f"\nğŸ” ì–¼êµ´ ë¹„êµ ìš”ì²­ - íŒŒì¼: {file.filename}")

    try:
        # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ì²˜ë¦¬
        image_array = await process_uploaded_image(file)
        print(f"ğŸ–¼ï¸ ì—…ë¡œë“œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ - í¬ê¸°: {image_array.shape}")

        # ìƒˆ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ
        new_face_embedding = extract_face_embedding(image_array)

        if new_face_embedding is None:
            print(f"âŒ ì—…ë¡œë“œ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨")
            return FaceCompareResponse(
                success=False,
                message="ì—…ë¡œë“œëœ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª…í™•í•œ ì–¼êµ´ ì‚¬ì§„ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.",
                is_same_person=False
            )

        # base64 í…ìŠ¤íŠ¸ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
        try:
            face_bytes = base64.b64decode(base64_text.encode('utf-8'))
            stored_face_embedding = np.frombuffer(face_bytes, dtype=np.float64)
            print(f"ğŸ“Š base64ì—ì„œ ë³µì›ëœ ì„ë² ë”© í¬ê¸°: {stored_face_embedding.shape}")
        except Exception as e:
            print(f"âŒ base64 í…ìŠ¤íŠ¸ ë””ì½”ë”© ì‹¤íŒ¨: {str(e)}")
            return FaceCompareResponse(
                success=False,
                message="ì˜ëª»ëœ base64 í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.",
                is_same_person=False
            )

        print(f"ğŸ“Š ìƒˆë¡œìš´ ì„ë² ë”© í¬ê¸°: {new_face_embedding.shape}")

        # ì–¼êµ´ ë¹„êµ
        print(f"ğŸ”„ ì–¼êµ´ ìœ ì‚¬ë„ ë¹„êµ ì¤‘...")
        is_match, confidence = compare_faces_deepface(stored_face_embedding, new_face_embedding)

        print(f"ğŸ“ˆ ìœ ì‚¬ë„ ì ìˆ˜: {confidence:.2f}%")
        print(f"ğŸ¯ ì„ê³„ê°’: 60.0%")

        if is_match:
            print(f"âœ… ë™ì¼ ì¸ë¬¼ í™•ì¸! (ì‹ ë¢°ë„: {confidence:.2f}%)")
            return FaceCompareResponse(
                success=True,
                message="ë™ì¼í•œ ì¸ë¬¼ì…ë‹ˆë‹¤.",
                is_same_person=True,
                confidence=round(confidence, 2)
            )
        else:
            print(f"âŒ ë‹¤ë¥¸ ì¸ë¬¼ (ì‹ ë¢°ë„: {confidence:.2f}% < 60.0%)")
            return FaceCompareResponse(
                success=True,
                message="ë‹¤ë¥¸ ì¸ë¬¼ì…ë‹ˆë‹¤.",
                is_same_person=False,
                confidence=round(confidence, 2)
            )

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ì–¼êµ´ ë¹„êµ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì–¼êµ´ ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8100)