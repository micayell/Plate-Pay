import * as tf from '@tensorflow/tfjs';
import '@tensorflow/tfjs-backend-webgl';
import '@tensorflow/tfjs-backend-cpu';

export interface Detection {
  bbox: [number, number, number, number]; // [x1, y1, x2, y2]
  class: string;
  confidence: number;
  classId: number;
}

export interface LicensePlateDetection {
  bbox: [number, number, number, number]; // [x1, y1, x2, y2]
  confidence: number;
  vehicleId: number;
  plateText?: string;
  source: 'estimated' | 'yolo'; // ë²ˆí˜¸íŒ ê°ì§€ ë°©ë²•
}

export class YOLOv8PlateDetector {
  private model: tf.GraphModel | null = null;
  private isLoaded = false;
  private inputSize = 640; // YOLOv8 í‘œì¤€ ì…ë ¥ í¬ê¸°

  async loadModel(onProgress?: (progress: number) => void): Promise<void> {
    try {
      console.log('ğŸ¯ YOLOv8 ë²ˆí˜¸íŒ ê°ì§€ ëª¨ë¸ ë¡œë”© ì‹œì‘...');

      await tf.ready();
      if (onProgress) onProgress(20);

      // ONNXë¥¼ TensorFlow.jsë¡œ ë³€í™˜ëœ ëª¨ë¸ ì‹œë„
      const modelUrls = [
        '/models/license_plate_detector_tfjs/model.json', // ONNX â†’ TF.js ë³€í™˜
        '/models/yolov8_plate_tfjs/model.json', // YOLOv8 TF.js ë²„ì „
      ];

      let modelLoaded = false;
      for (const modelUrl of modelUrls) {
        try {
          console.log(`ğŸ” TensorFlow.js ëª¨ë¸ ë¡œë“œ ì‹œë„: ${modelUrl}`);

          this.model = await tf.loadGraphModel(modelUrl);

          console.log(`âœ… YOLOv8 ëª¨ë¸ ë¡œë“œ ì„±ê³µ: ${modelUrl}`);
          console.log(`ğŸ“‹ ì…ë ¥ í˜•íƒœ:`, this.model.inputs.map(i => i.shape));
          console.log(`ğŸ“¤ ì¶œë ¥ í˜•íƒœ:`, this.model.outputs.map(o => o.shape));

          modelLoaded = true;
          break;

        } catch (error) {
          console.warn(`âš ï¸ ${modelUrl} ë¡œë“œ ì‹¤íŒ¨:`, error);
        }
      }

      if (!modelLoaded) {
        console.warn('âš ï¸ TensorFlow.js ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, Computer Vision ëª¨ë“œë¡œ ëŒ€ì²´');
        // Computer Vision ë°±ì—… ëª¨ë“œ
      }

      if (onProgress) onProgress(100);
      this.isLoaded = true;

      console.log('âœ… YOLOv8 ë²ˆí˜¸íŒ ê°ì§€ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ');

    } catch (error) {
      console.error('âŒ YOLOv8 ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  async detectLicensePlates(canvas: HTMLCanvasElement): Promise<LicensePlateDetection[]> {
    if (!this.isLoaded) {
      console.warn('âš ï¸ YOLOv8 ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ');
      return [];
    }

    try {
      if (this.model) {
        // YOLOv8 TensorFlow.js ëª¨ë¸ ì‚¬ìš©
        return await this.detectWithYOLOv8TF(canvas);
      } else {
        // Computer Vision ë°±ì—… ëª¨ë“œ
        return await this.detectWithComputerVision(canvas);
      }
    } catch (error) {
      console.error('âŒ ë²ˆí˜¸íŒ ê°ì§€ ì˜¤ë¥˜:', error);
      return [];
    }
  }

  private async detectWithYOLOv8TF(canvas: HTMLCanvasElement): Promise<LicensePlateDetection[]> {
    if (!this.model) return [];

    console.log('ğŸ¯ YOLOv8 TensorFlow.jsë¡œ ë²ˆí˜¸íŒ ê°ì§€ ì‹œì‘...');

    // 1. ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬
    const inputTensor = this.preprocessImageTF(canvas);

    // 2. YOLOv8 ì¶”ë¡  ì‹¤í–‰
    const prediction = this.model.predict(inputTensor) as tf.Tensor;

    // 3. í›„ì²˜ë¦¬ - YOLOv8 ì¶œë ¥ì„ ë²ˆí˜¸íŒ ê°ì§€ ê²°ê³¼ë¡œ ë³€í™˜
    const outputData = await prediction.data();
    const plateDetections = this.postprocessYOLOv8OutputTF(
      outputData as Float32Array,
      prediction.shape,
      canvas.width,
      canvas.height
    );

    // ë©”ëª¨ë¦¬ ì •ë¦¬
    inputTensor.dispose();
    prediction.dispose();

    console.log(`âœ… YOLOv8 TensorFlow.js ê°ì§€ ì™„ë£Œ: ${plateDetections.length}ê°œ ë²ˆí˜¸íŒ`);
    return plateDetections;
  }

  private preprocessImageTF(canvas: HTMLCanvasElement): tf.Tensor {
    // TensorFlow.jsë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    console.log('ğŸ“Š TensorFlow.js ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹œì‘...');

    // Canvasì—ì„œ ì§ì ‘ í…ì„œ ìƒì„±
    const imageTensor = tf.browser.fromPixels(canvas)
      .resizeNearestNeighbor([this.inputSize, this.inputSize]) // 640x640ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
      .expandDims(0) // ë°°ì¹˜ ì°¨ì› ì¶”ê°€ [1, 640, 640, 3]
      .div(255.0) // ì •ê·œí™” (0-1 ë²”ìœ„)
      .transpose([0, 3, 1, 2]); // [1, 3, 640, 640] - YOLOv8 ì…ë ¥ í˜•ì‹

    console.log('ğŸ“Š ì…ë ¥ í…ì„œ í˜•íƒœ:', imageTensor.shape);
    return imageTensor;
  }

  private postprocessYOLOv8OutputTF(
    output: Float32Array,
    outputShape: number[],
    originalWidth: number,
    originalHeight: number
  ): LicensePlateDetection[] {
    console.log('ğŸ“Š YOLOv8 TensorFlow.js ì¶œë ¥ í˜•íƒœ:', outputShape);

    // YOLOv8 ì¶œë ¥ í˜•ì‹: [1, 5, 8400] ë˜ëŠ” [1, 8400, 5]
    const plateDetections: LicensePlateDetection[] = [];
    const confidenceThreshold = 0.3; // ì‹ ë¢°ë„ ì„ê³„ê°’ ë‚®ì¶¤

    let numDetections = 0;
    let featuresPerDetection = 0;

    // ì¶œë ¥ í˜•íƒœì— ë”°ë¼ ì°¨ì› ê²°ì •
    if (outputShape.length === 3) {
      if (outputShape[1] === 5) {
        // [1, 5, 8400] í˜•íƒœ
        featuresPerDetection = outputShape[1];
        numDetections = outputShape[2];
      } else {
        // [1, 8400, 5] í˜•íƒœ
        numDetections = outputShape[1];
        featuresPerDetection = outputShape[2];
      }
    }

    console.log(`ğŸ“Š ê°ì§€ ê²°ê³¼ ë¶„ì„: ${numDetections}ê°œ í›„ë³´, ${featuresPerDetection}ê°œ íŠ¹ì„±`);

    // ìŠ¤ì¼€ì¼ ê³„ì‚° (ì…ë ¥ í¬ê¸° â†’ ì›ë³¸ í¬ê¸°)
    const scaleX = originalWidth / this.inputSize;
    const scaleY = originalHeight / this.inputSize;

    for (let i = 0; i < numDetections; i++) {
      let x, y, w, h, confidence;

      // ì¶œë ¥ í˜•íƒœì— ë”°ë¼ ë°ì´í„° ì¶”ì¶œ ë°©ì‹ ê²°ì •
      if (outputShape[1] === 5) {
        // [1, 5, 8400] í˜•íƒœ
        x = output[i];
        y = output[numDetections + i];
        w = output[2 * numDetections + i];
        h = output[3 * numDetections + i];
        confidence = output[4 * numDetections + i];
      } else {
        // [1, 8400, 5] í˜•íƒœ
        const baseIndex = i * featuresPerDetection;
        x = output[baseIndex];
        y = output[baseIndex + 1];
        w = output[baseIndex + 2];
        h = output[baseIndex + 3];
        confidence = output[baseIndex + 4];
      }

      if (confidence > confidenceThreshold) {
        // ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ê³„ì‚° (ì¤‘ì‹¬ â†’ ì¢Œìƒë‹¨/ìš°í•˜ë‹¨)
        const x1 = (x - w / 2) * scaleX;
        const y1 = (y - h / 2) * scaleY;
        const x2 = (x + w / 2) * scaleX;
        const y2 = (y + h / 2) * scaleY;

        // ìœ íš¨í•œ ë°”ìš´ë”© ë°•ìŠ¤ì¸ì§€ í™•ì¸
        if (x2 > x1 && y2 > y1 && x1 >= 0 && y1 >= 0 && x2 <= originalWidth && y2 <= originalHeight) {
          plateDetections.push({
            bbox: [x1, y1, x2, y2],
            confidence: confidence,
            vehicleId: i,
            source: 'yolo'
          });

          console.log(`âœ… YOLOv8 TF.js ë²ˆí˜¸íŒ ê°ì§€: (${x1.toFixed(1)}, ${y1.toFixed(1)}) â†’ (${x2.toFixed(1)}, ${y2.toFixed(1)}), ì‹ ë¢°ë„: ${(confidence * 100).toFixed(1)}%`);
        }
      }
    }

    // ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    plateDetections.sort((a, b) => b.confidence - a.confidence);

    return plateDetections.slice(0, 5); // ìµœëŒ€ 5ê°œê¹Œì§€
  }

  private async detectWithComputerVision(canvas: HTMLCanvasElement): Promise<LicensePlateDetection[]> {
    console.log('ğŸ¯ ì‹¤ì‹œê°„ ë²ˆí˜¸íŒ ê°ì§€ ì‹œì‘...');

    const ctx = canvas.getContext('2d');
    if (!ctx) return [];

    // ì´ë¯¸ì§€ ë°ì´í„° íšë“
    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

    // ë²ˆí˜¸íŒ íŠ¹ì„±ì„ ì´ìš©í•œ ê°ì§€
    const plateRegions = this.detectPlateRegions(imageData, canvas.width, canvas.height);

    console.log(`ğŸ” ${plateRegions.length}ê°œ ë²ˆí˜¸íŒ í›„ë³´ ì˜ì—­ ë°œê²¬`);

    return plateRegions;
  }

  private detectPlateRegions(imageData: ImageData, width: number, height: number): LicensePlateDetection[] {
    const plateDetections: LicensePlateDetection[] = [];

    // ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    const grayData = this.convertToGrayscale(imageData);

    // ì—ì§€ ê°ì§€ (ì†Œë²¨ í•„í„°)
    const edges = this.detectEdges(grayData, width, height);

    // ìˆ˜í‰ ë¼ì¸ ê°•ì¡° (ë²ˆí˜¸íŒì˜ íŠ¹ì§•)
    const horizontalLines = this.enhanceHorizontalLines(edges, width, height);

    // ì—°ê²° ì»´í¬ë„ŒíŠ¸ ë¶„ì„ìœ¼ë¡œ ë²ˆí˜¸íŒ í›„ë³´ ì˜ì—­ ì°¾ê¸°
    const candidates = this.findPlateCanidates(horizontalLines, width, height);

    // ë²ˆí˜¸íŒ í¬ê¸°/ë¹„ìœ¨ í•„í„°ë§
    const validPlates = this.filterByPlateCharacteristics(candidates, width, height);

    console.log(`ğŸ“Š ê°ì§€ ê³¼ì •: ${candidates.length}ê°œ í›„ë³´ â†’ ${validPlates.length}ê°œ ìœ íš¨í•œ ë²ˆí˜¸íŒ`);

    return validPlates;
  }

  private convertToGrayscale(imageData: ImageData): Uint8Array {
    const grayData = new Uint8Array(imageData.width * imageData.height);
    const data = imageData.data;

    for (let i = 0; i < data.length; i += 4) {
      // RGBë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜ (ê°€ì¤‘ í‰ê· )
      const gray = Math.round(0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2]);
      grayData[i / 4] = gray;
    }

    return grayData;
  }

  private detectEdges(grayData: Uint8Array, width: number, height: number): Uint8Array {
    const edges = new Uint8Array(width * height);

    // ì†Œë²¨ í•„í„° ì»¤ë„
    const sobelX = [-1, 0, 1, -2, 0, 2, -1, 0, 1];
    const sobelY = [-1, -2, -1, 0, 0, 0, 1, 2, 1];

    for (let y = 1; y < height - 1; y++) {
      for (let x = 1; x < width - 1; x++) {
        let gx = 0, gy = 0;

        // 3x3 ì»¤ë„ ì ìš©
        for (let ky = 0; ky < 3; ky++) {
          for (let kx = 0; kx < 3; kx++) {
            const pixel = grayData[(y + ky - 1) * width + (x + kx - 1)];
            const kernelIndex = ky * 3 + kx;
            gx += pixel * sobelX[kernelIndex];
            gy += pixel * sobelY[kernelIndex];
          }
        }

        // ê·¸ë˜ë””ì–¸íŠ¸ í¬ê¸° ê³„ì‚°
        const magnitude = Math.sqrt(gx * gx + gy * gy);
        edges[y * width + x] = Math.min(255, magnitude);
      }
    }

    return edges;
  }

  private enhanceHorizontalLines(edges: Uint8Array, width: number, height: number): Uint8Array {
    const enhanced = new Uint8Array(width * height);

    // ìˆ˜í‰ ë¼ì¸ ê°•ì¡° ì»¤ë„ (ë²ˆí˜¸íŒì€ ìˆ˜í‰ ì—ì§€ê°€ ê°•í•¨)
    const horizontalKernel = [-1, -1, -1, 2, 2, 2, -1, -1, -1];

    for (let y = 1; y < height - 1; y++) {
      for (let x = 1; x < width - 1; x++) {
        let sum = 0;

        for (let ky = 0; ky < 3; ky++) {
          for (let kx = 0; kx < 3; kx++) {
            const pixel = edges[(y + ky - 1) * width + (x + kx - 1)];
            sum += pixel * horizontalKernel[ky * 3 + kx];
          }
        }

        enhanced[y * width + x] = Math.max(0, Math.min(255, sum / 9));
      }
    }

    return enhanced;
  }

  private findPlateCanidates(enhanced: Uint8Array, width: number, height: number): Array<{x: number, y: number, w: number, h: number, intensity: number}> {
    const candidates = [];
    const threshold = 100; // ì„ê³„ê°’
    const visited = new Set<number>();

    // ì—°ê²° ì»´í¬ë„ŒíŠ¸ ë¶„ì„
    for (let y = 0; y < height; y++) {
      for (let x = 0; x < width; x++) {
        const index = y * width + x;

        if (enhanced[index] > threshold && !visited.has(index)) {
          const component = this.floodFill(enhanced, width, height, x, y, threshold, visited);

          if (component.pixels.length > 100) { // ìµœì†Œ í¬ê¸° í•„í„°
            const bounds = this.getBoundingBox(component.pixels);
            candidates.push({
              x: bounds.minX,
              y: bounds.minY,
              w: bounds.maxX - bounds.minX,
              h: bounds.maxY - bounds.minY,
              intensity: component.avgIntensity
            });
          }
        }
      }
    }

    return candidates;
  }

  private floodFill(data: Uint8Array, width: number, height: number, startX: number, startY: number, threshold: number, visited: Set<number>) {
    const pixels = [];
    const stack = [{x: startX, y: startY}];
    let totalIntensity = 0;

    while (stack.length > 0) {
      const {x, y} = stack.pop()!;
      const index = y * width + x;

      if (x < 0 || x >= width || y < 0 || y >= height || visited.has(index) || data[index] <= threshold) {
        continue;
      }

      visited.add(index);
      pixels.push({x, y});
      totalIntensity += data[index];

      // 8ë°©í–¥ íƒìƒ‰
      stack.push({x: x + 1, y}, {x: x - 1, y}, {x, y: y + 1}, {x, y: y - 1});
      stack.push({x: x + 1, y: y + 1}, {x: x - 1, y: y - 1}, {x: x + 1, y: y - 1}, {x: x - 1, y: y + 1});
    }

    return {
      pixels,
      avgIntensity: pixels.length > 0 ? totalIntensity / pixels.length : 0
    };
  }

  private getBoundingBox(pixels: Array<{x: number, y: number}>) {
    let minX = Infinity, maxX = -Infinity, minY = Infinity, maxY = -Infinity;

    for (const pixel of pixels) {
      minX = Math.min(minX, pixel.x);
      maxX = Math.max(maxX, pixel.x);
      minY = Math.min(minY, pixel.y);
      maxY = Math.max(maxY, pixel.y);
    }

    return {minX, maxX, minY, maxY};
  }

  private filterByPlateCharacteristics(candidates: Array<{x: number, y: number, w: number, h: number, intensity: number}>, imageWidth: number, imageHeight: number): LicensePlateDetection[] {
    const validPlates: LicensePlateDetection[] = [];

    for (const candidate of candidates) {
      const aspectRatio = candidate.w / candidate.h;
      const area = candidate.w * candidate.h;
      const relativeSize = area / (imageWidth * imageHeight);

      // í•œêµ­ ë²ˆí˜¸íŒ íŠ¹ì„± í•„í„°ë§
      // - ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨: 2:1 ~ 5:1
      // - ìµœì†Œ í¬ê¸°: ì „ì²´ ì´ë¯¸ì§€ì˜ 0.5%
      // - ìµœëŒ€ í¬ê¸°: ì „ì²´ ì´ë¯¸ì§€ì˜ 20%

      if (aspectRatio >= 2.0 && aspectRatio <= 5.0 &&
          relativeSize >= 0.005 && relativeSize <= 0.2 &&
          candidate.w >= 80 && candidate.h >= 20) {

        // ì‹ ë¢°ë„ ê³„ì‚° (í¬ê¸°, ë¹„ìœ¨, ê°•ë„ ê¸°ë°˜)
        const sizeScore = Math.min(1.0, relativeSize / 0.05); // 5%ì¼ ë•Œ ë§Œì 
        const ratioScore = Math.max(0, 1.0 - Math.abs(aspectRatio - 3.5) / 2.5); // 3.5:1ì´ ì´ìƒì 
        const intensityScore = candidate.intensity / 255;

        const confidence = (sizeScore * 0.4 + ratioScore * 0.4 + intensityScore * 0.2);

        if (confidence > 0.3) {
          validPlates.push({
            bbox: [candidate.x, candidate.y, candidate.x + candidate.w, candidate.y + candidate.h],
            confidence: Math.min(0.95, confidence),
            vehicleId: 0,
            source: 'yolo'
          });

          console.log(`âœ… ë²ˆí˜¸íŒ ê°ì§€: (${candidate.x}, ${candidate.y}) ${candidate.w}x${candidate.h}, ë¹„ìœ¨: ${aspectRatio.toFixed(2)}, ì‹ ë¢°ë„: ${(confidence * 100).toFixed(1)}%`);
        }
      }
    }

    // ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ìˆœ)
    validPlates.sort((a, b) => b.confidence - a.confidence);

    // ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ë°˜í™˜
    return validPlates.slice(0, 3);
  }

  private async processModelOutput(predictions: tf.Tensor | tf.Tensor[], canvasWidth: number, canvasHeight: number): Promise<LicensePlateDetection[]> {
    try {
      console.log('ğŸ“Š ì‹¤ì œ ANPR ëª¨ë¸ ì¶œë ¥ ì²˜ë¦¬ ì¤‘...');

      let outputTensor: tf.Tensor;
      if (Array.isArray(predictions)) {
        outputTensor = predictions[0]; // ì²« ë²ˆì§¸ ì¶œë ¥ ì‚¬ìš©
      } else {
        outputTensor = predictions;
      }

      const outputData = await outputTensor.data();
      console.log('ğŸ¯ ëª¨ë¸ ì¶œë ¥:', outputData.length, 'ê°œ ê°’');

      // WPOD-Net ìŠ¤íƒ€ì¼ ì¶œë ¥ ì²˜ë¦¬ (4ê°œ ê°’: x1, y1, x2, y2)
      if (outputData.length === 4) {
        const x1 = outputData[0];
        const y1 = outputData[1];
        const x2 = outputData[2];
        const y2 = outputData[3];

        // ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ ì‹¤ì œ í¬ê¸°ë¡œ ë³€í™˜
        const actualX1 = x1 * canvasWidth;
        const actualY1 = y1 * canvasHeight;
        const actualX2 = x2 * canvasWidth;
        const actualY2 = y2 * canvasHeight;

        // ìœ íš¨í•œ ë°”ìš´ë”© ë°•ìŠ¤ì¸ì§€ í™•ì¸
        if (actualX2 > actualX1 && actualY2 > actualY1) {
          const confidence = Math.min(x2 - x1, y2 - y1); // í¬ê¸° ê¸°ë°˜ ì‹ ë¢°ë„

          console.log(`âœ… ë²ˆí˜¸íŒ ê°ì§€: (${actualX1.toFixed(1)}, ${actualY1.toFixed(1)}) â†’ (${actualX2.toFixed(1)}, ${actualY2.toFixed(1)})`);

          return [{
            bbox: [actualX1, actualY1, actualX2, actualY2],
            confidence: Math.max(0.5, Math.min(0.95, confidence * 2)), // 50-95% ë²”ìœ„
            vehicleId: 0,
            source: 'yolo'
          }];
        }
      }

      console.log('âš ï¸ ëª¨ë¸ ì¶œë ¥ì—ì„œ ìœ íš¨í•œ ë²ˆí˜¸íŒ ì˜ì—­ì„ ì°¾ì§€ ëª»í•¨');
      return [];

    } catch (error) {
      console.error('âŒ ëª¨ë¸ ì¶œë ¥ ì²˜ë¦¬ ì˜¤ë¥˜:', error);
      return [];
    }
  }


  dispose(): void {
    if (this.model) {
      this.model.dispose();
      this.model = null;
    }
    this.isLoaded = false;
  }
}

export class ANPRDetector {
  private plateDetector: YOLOv8PlateDetector | null = null;
  private isLoaded = false;

  async loadModel(onProgress?: (progress: number) => void): Promise<void> {
    try {
      console.log('ğŸ”¢ ANPR ì „ìš© ëª¨ë¸ ë¡œë”© ì‹œì‘...');

      // TensorFlow.js ë°±ì—”ë“œ ì´ˆê¸°í™”
      await tf.ready();
      console.log('âœ… TensorFlow.js ì¤€ë¹„ ì™„ë£Œ');
      console.log('ì‚¬ìš© ê°€ëŠ¥í•œ ë°±ì—”ë“œ:', tf.getBackend());

      if (onProgress) onProgress(30);

      // YOLOv8 ANPR ëª¨ë¸ ë¡œë“œ
      this.plateDetector = new YOLOv8PlateDetector();
      await this.plateDetector.loadModel();
      console.log('âœ… ANPR ëª¨ë¸ ë¡œë“œ ì™„ë£Œ');

      if (onProgress) onProgress(100);

      this.isLoaded = true;
      console.log('âœ… ANPR ì „ìš© ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ');

    } catch (error) {
      console.error('âŒ ANPR ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  async detectLicensePlates(videoElement: HTMLVideoElement, displayWidth: number = 1280, displayHeight: number = 1080): Promise<LicensePlateDetection[]> {
    if (!this.plateDetector || !this.isLoaded) {
      console.warn('âš ï¸ ANPR ëª¨ë¸ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•ŠìŒ');
      return [];
    }

    try {
      console.log('ğŸ¯ ANPR ëª¨ë¸ë¡œ ì§ì ‘ ë²ˆí˜¸íŒ ê°ì§€ ì‹œì‘...');

      // ì „ì²´ í™”ë©´ì„ ANPR ëª¨ë¸ë¡œ ì§ì ‘ ë¶„ì„
      const canvas = this.cropVideoToDisplayArea(videoElement, displayWidth, displayHeight);
      const plateDetections = await this.plateDetector.detectLicensePlates(canvas);

      // ì¢Œí‘œë¥¼ í‘œì‹œ í¬ê¸°ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§
      const scaledPlateDetections = plateDetections.map(plate => ({
        ...plate,
        bbox: [
          plate.bbox[0] * 0.5, // x1
          plate.bbox[1] * 0.5, // y1
          plate.bbox[2] * 0.5, // x2
          plate.bbox[3] * 0.5  // y2
        ] as [number, number, number, number]
      }));

      console.log(`âœ… ANPR ì§ì ‘ ê°ì§€ ê²°ê³¼: ${scaledPlateDetections.length}ê°œ ë²ˆí˜¸íŒ`);
      return scaledPlateDetections;

    } catch (error) {
      console.error('âŒ ANPR ê°ì§€ ì˜¤ë¥˜:', error);
      return [];
    }
  }

  // 2ë‹¨ê³„ ë²ˆí˜¸íŒ ê°ì§€: 1) YOLO11ë¡œ ì •í™•íˆ ê°ì§€ ì‹œë„ 2) ì‹¤íŒ¨ì‹œ ì¶”ì • ë°©ì‹ ì‚¬ìš©
  async detectLicensePlatesFromVehicles(vehicleDetections: Detection[], videoElement: HTMLVideoElement): Promise<LicensePlateDetection[]> {
    const plateDetections: LicensePlateDetection[] = [];

    for (let index = 0; index < vehicleDetections.length; index++) {
      const vehicle = vehicleDetections[index];

      // ì°¨ëŸ‰ì´ ì•„ë‹Œ ê²½ìš° ìŠ¤í‚µ
      if (!['car', 'truck', 'bus', 'motorcycle', 'motorbike'].includes(vehicle.class)) {
        continue;
      }

      const [x1, y1, x2, y2] = vehicle.bbox;

      // 1ë‹¨ê³„: YOLO11 ANPR ëª¨ë¸ë¡œ ì •í™•í•œ ê°ì§€ ì‹œë„
      if (this.plateDetector) {
        try {
          console.log(`ğŸ¯ ì°¨ëŸ‰ ${index+1}: YOLO11ë¡œ ë²ˆí˜¸íŒ ê°ì§€ ì‹œë„...`);

          // ì°¨ëŸ‰ ì˜ì—­ í¬ë¡­
          const croppedCanvas = this.cropVehicleArea(videoElement, x1, y1, x2, y2);
          const yoloPlateDetections = await this.plateDetector.detectLicensePlates(croppedCanvas);

          if (yoloPlateDetections.length > 0) {
            // YOLO11 ê°ì§€ ì„±ê³µ - ì°¨ëŸ‰ ì¢Œí‘œê³„ë¡œ ë³€í™˜
            yoloPlateDetections.forEach(plateDet => {
              const [px1, py1, px2, py2] = plateDet.bbox;
              plateDetections.push({
                bbox: [x1 + px1, y1 + py1, x1 + px2, y1 + py2],
                confidence: plateDet.confidence,
                vehicleId: index,
                plateText: undefined,
                source: 'yolo'
              });
            });
            console.log(`âœ… ì°¨ëŸ‰ ${index+1}: YOLO11ë¡œ ${yoloPlateDetections.length}ê°œ ë²ˆí˜¸íŒ ê°ì§€ ì„±ê³µ`);
            continue;
          }
        } catch (error) {
          console.warn(`âš ï¸ ì°¨ëŸ‰ ${index+1}: YOLO11 ë²ˆí˜¸íŒ ê°ì§€ ì‹¤íŒ¨:`, error);
        }
      }

      // 2ë‹¨ê³„: YOLO11 ì‹¤íŒ¨ì‹œ ì¶”ì • ë°©ì‹ ì‚¬ìš©
      console.log(`ğŸ”„ ì°¨ëŸ‰ ${index+1}: ì¶”ì • ë°©ì‹ìœ¼ë¡œ ë²ˆí˜¸íŒ ìœ„ì¹˜ ê³„ì‚°...`);
      const vehicleWidth = x2 - x1;
      const vehicleHeight = y2 - y1;
      const plateRegions = this.estimatePlatePosition(vehicle.class, x1, y1, vehicleWidth, vehicleHeight);

      plateRegions.forEach((plateRegion) => {
        plateDetections.push({
          bbox: plateRegion.bbox,
          confidence: vehicle.confidence * plateRegion.confidence,
          vehicleId: index,
          plateText: undefined,
          source: 'estimated'
        });
      });
    }

    const yoloCount = plateDetections.filter(p => p.source === 'yolo').length;
    const estimatedCount = plateDetections.filter(p => p.source === 'estimated').length;
    console.log(`ğŸ” ë²ˆí˜¸íŒ ê°ì§€ ê²°ê³¼: YOLO11 ${yoloCount}ê°œ, ì¶”ì • ${estimatedCount}ê°œ (ì´ ${plateDetections.length}ê°œ)`);

    return plateDetections;
  }

  // ì°¨ëŸ‰ ì˜ì—­ì„ í¬ë¡­í•˜ì—¬ ìº”ë²„ìŠ¤ë¡œ ë°˜í™˜
  private cropVehicleArea(videoElement: HTMLVideoElement, x1: number, y1: number, x2: number, y2: number): HTMLCanvasElement {
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d')!;

    const width = x2 - x1;
    const height = y2 - y1;

    canvas.width = width;
    canvas.height = height;

    // ì°¨ëŸ‰ ì˜ì—­ë§Œ í¬ë¡­
    ctx.drawImage(videoElement, x1, y1, width, height, 0, 0, width, height);

    return canvas;
  }

  private estimatePlatePosition(vehicleClass: string, x: number, y: number, width: number, height: number) {
    const plateRegions = [];
    
    // ìˆ˜ì •ëœ ë²ˆí˜¸íŒ ì˜ì—­: ê¸°ì¡´ í•˜ë‹¨ 30%ì—ì„œ ì•„ë˜ 10% ì˜¬ë¦¬ê³  ìœ„ë¡œ 20% í™•ì¥ í›„ ì¶”ê°€ë¡œ 10% ë” ì˜¬ë¦¼, ê·¸ë¦¬ê³  7% ì•„ë˜ë¡œ
    // ê¸°ì¡´: í•˜ë‹¨ 30% (70%~100%) â†’ ìµœì¢…: 47%~87% (ì¤‘ì•™-í•˜ë‹¨ ì˜ì—­)
    const plateAreaHeight = height * 0.4; // ì°¨ëŸ‰ ë†’ì´ì˜ 40% (ê¸°ì¡´ 30%ì—ì„œ 10% ë” í™•ì¥)
    const plateAreaY = y + height * 0.47;  // ì°¨ëŸ‰ ìƒë‹¨ì—ì„œ 47% ì§€ì ë¶€í„° ì‹œì‘ (ê¸°ì¡´ 40%ì—ì„œ 7% ì•„ë˜ë¡œ)
    
    // ì¢Œìš° 15%ì”© ì œì™¸í•œ ê°€ìš´ë° 70% ì˜ì—­
    const horizontalMargin = width * 0.15; // ì¢Œìš° ê° 15%
    const plateAreaX = x + horizontalMargin; // ì™¼ìª½ 15% ì œì™¸
    const plateAreaWidth = width * 0.7; // ê°€ìš´ë° 70%ë§Œ ì‚¬ìš©
    
    plateRegions.push({
      bbox: [plateAreaX, plateAreaY, plateAreaX + plateAreaWidth, plateAreaY + plateAreaHeight] as [number, number, number, number],
      confidence: 0.9, // ë†’ì€ ì‹ ë¢°ë„ 
      position: 'bottom_center'
    });
    
    console.log(`ğŸ“‹ ${vehicleClass} ë²ˆí˜¸íŒ ì˜ì—­(ìˆ˜ì •ëœ ì¤‘ì•™40%+ì¤‘ì•™70%): (${plateAreaX.toFixed(1)}, ${plateAreaY.toFixed(1)}) ~ (${(plateAreaX + plateAreaWidth).toFixed(1)}, ${(plateAreaY + plateAreaHeight).toFixed(1)})`);
    
    return plateRegions;
  }

  private cropVideoToDisplayArea(videoElement: HTMLVideoElement, displayWidth: number, displayHeight: number): HTMLCanvasElement {
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d')!;
    
    canvas.width = displayWidth;
    canvas.height = displayHeight;
    
    // ë¹„ë””ì˜¤ì˜ ì‹¤ì œ í¬ê¸°
    const videoWidth = videoElement.videoWidth;
    const videoHeight = videoElement.videoHeight;
    
    // ë¹„ë””ì˜¤ê°€ ì–´ë–»ê²Œ í™”ë©´ì— ë§ì¶°ì§€ëŠ”ì§€ ê³„ì‚° (object-fit: cover)
    const videoAspect = videoWidth / videoHeight;
    const displayAspect = displayWidth / displayHeight;
    
    let sourceX = 0, sourceY = 0, sourceWidth = videoWidth, sourceHeight = videoHeight;
    
    if (videoAspect > displayAspect) {
      // ë¹„ë””ì˜¤ê°€ ë” ë„“ìŒ - ì¢Œìš°ê°€ ì˜ë¦¼
      sourceWidth = videoHeight * displayAspect;
      sourceX = (videoWidth - sourceWidth) / 2;
    } else {
      // ë¹„ë””ì˜¤ê°€ ë” ë†’ìŒ - ìƒí•˜ê°€ ì˜ë¦¼
      sourceHeight = videoWidth / displayAspect;
      sourceY = (videoHeight - sourceHeight) / 2;
    }
    
    // ì‹¤ì œ ë³´ì´ëŠ” ì˜ì—­ë§Œ ìº”ë²„ìŠ¤ì— ê·¸ë¦¬ê¸°
    ctx.drawImage(
      videoElement,
      sourceX, sourceY, sourceWidth, sourceHeight,  // ì†ŒìŠ¤ ì˜ì—­
      0, 0, displayWidth, displayHeight             // ëŒ€ìƒ ì˜ì—­
    );
    
    console.log(`ğŸ“· í¬ë¡­ ì •ë³´: ì›ë³¸(${videoWidth}x${videoHeight}) â†’ í‘œì‹œ(${displayWidth}x${displayHeight})`);
    console.log(`ğŸ“· ì†ŒìŠ¤ ì˜ì—­: x=${sourceX}, y=${sourceY}, w=${sourceWidth}, h=${sourceHeight}`);
    
    return canvas;
  }

  private convertCocoSsdResults(predictions: any[], videoWidth: number, videoHeight: number): Detection[] {
    // ì°¨ëŸ‰ê³¼ ê´€ë ¨ëœ í´ë˜ìŠ¤ë§Œ í•„í„°ë§ (ë” ë„“ì€ ë²”ìœ„)
    const vehicleClasses = ['car', 'motorcycle', 'bus', 'truck', 'bicycle', 'motorbike'];
    
    console.log(`ğŸ“Š COCO-SSD ì›ë³¸ ê²°ê³¼: ${predictions.length}ê°œ ê°ì²´`);
    
    const results = predictions
      .filter(pred => vehicleClasses.includes(pred.class.toLowerCase()) && pred.score > 0.15) // ì„ê³„ê°’ ë” ë‚®ì¶¤
      .map((pred, index) => {
        const [x, y, width, height] = pred.bbox;
        
        console.log(`ğŸ” ì›ë³¸ ê°ì§€: ${pred.class} at (${x.toFixed(1)}, ${y.toFixed(1)}, ${width.toFixed(1)}, ${height.toFixed(1)}) conf=${pred.score.toFixed(3)}`);
        
        // ì¢Œìš° ë°˜ì „ëœ í™”ë©´ì— ë§ì¶° ì¢Œí‘œ ì¡°ì •
        const flippedX = videoWidth - (x + width);
        
        console.log(`ğŸ”„ ë°˜ì „ í›„: ${pred.class} at (${flippedX.toFixed(1)}, ${y.toFixed(1)}, ${width.toFixed(1)}, ${height.toFixed(1)})`);
        
        return {
          bbox: [flippedX, y, flippedX + width, y + height] as [number, number, number, number],
          class: pred.class.toLowerCase(),
          confidence: pred.score,
          classId: this.getClassId(pred.class.toLowerCase())
        };
      });
    
    console.log(`âœ… ìµœì¢… ê²°ê³¼: ${results.length}ê°œ ê°ì²´`);
    return results;
  }

  private async detectWithCustomModel(videoElement: HTMLVideoElement, displayWidth: number = 1280, displayHeight: number = 1080): Promise<Detection[]> {
    try {
      // ì‹¤ì œ ë³´ì´ëŠ” ì˜ì—­ë§Œ í¬ë¡­
      const croppedCanvas = this.cropVideoToDisplayArea(videoElement, displayWidth, displayHeight);
      
      // í¬ë¡­ëœ ìº”ë²„ìŠ¤ë¥¼ ê³ í•´ìƒë„(1280x1280) í…ì„œë¡œ ë³€í™˜í•˜ì—¬ í’ˆì§ˆ í–¥ìƒ
      const tensor = tf.browser.fromPixels(croppedCanvas)
        .resizeNearestNeighbor([1280, 1280])
        .expandDims(0)
        .div(255.0);

      console.log('ğŸ“Š ì…ë ¥ í…ì„œ:', tensor.shape);

      // ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
      const predictions = await (this.plateDetector as any).model.predict(tensor) as tf.Tensor;
      
      // ê²°ê³¼ ì²˜ë¦¬ (YOLOv8 ì¶œë ¥ í˜•íƒœì— ë”°ë¼)
      const detections = await this.processCustomModelOutput(predictions, displayWidth, displayHeight);
      
      // ë©”ëª¨ë¦¬ ì •ë¦¬
      tensor.dispose();
      predictions.dispose();
      
      return detections;
      
    } catch (error) {
      console.error('âŒ ì»¤ìŠ¤í…€ ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨:', error);
      return [];
    }
  }

  private async processCustomModelOutput(predictions: tf.Tensor, videoWidth: number, videoHeight: number): Promise<Detection[]> {
    // YOLOv8 ì¶œë ¥ ì²˜ë¦¬ ë¡œì§
    // ì‹¤ì œ êµ¬í˜„ì€ ëª¨ë¸ êµ¬ì¡°ì— ë”°ë¼ ë‹¬ë¼ì§
    
    try {
      const data = await predictions.data();
      console.log('ğŸ“Š ì»¤ìŠ¤í…€ ëª¨ë¸ ì¶œë ¥ í¬ê¸°:', data.length);
      
      // ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ëŒ€ì²´
      // ì‹¤ì œë¡œëŠ” YOLOv8 ì¶œë ¥ í˜•íƒœì— ë§ê²Œ íŒŒì‹±í•´ì•¼ í•¨
      return this.simulateDetections(videoWidth, videoHeight);
      
    } catch (error) {
      console.error('âŒ ì¶œë ¥ ì²˜ë¦¬ ì˜¤ë¥˜:', error);
      return [];
    }
  }

  private simulateDetections(videoWidth: number, videoHeight: number): Detection[] {
    // ê°œë°œìš© ì‹œë®¬ë ˆì´ì…˜
    const detections: Detection[] = [];
    
    if (Math.random() > 0.7) { // 30% í™•ë¥ ë¡œ ê°ì§€
      const classes = ['car', 'truck', 'bus', 'motorcycle'];
      const selectedClass = classes[Math.floor(Math.random() * classes.length)];
      
      const x1 = Math.random() * videoWidth * 0.3;
      const y1 = Math.random() * videoHeight * 0.3;
      const x2 = x1 + videoWidth * 0.4;
      const y2 = y1 + videoHeight * 0.4;
      
      // ì¢Œìš° ë°˜ì „ëœ í™”ë©´ì— ë§ì¶° ì¢Œí‘œ ì¡°ì •
      const flippedX1 = videoWidth - x2;
      const flippedX2 = videoWidth - x1;
      
      detections.push({
        bbox: [flippedX1, y1, flippedX2, y2] as [number, number, number, number],
        class: selectedClass,
        confidence: 0.6 + Math.random() * 0.3,
        classId: this.getClassId(selectedClass)
      });
    }
    
    return detections;
  }

  private getClassId(className: string): number {
    const classMap: { [key: string]: number } = {
      'bicycle': 1,
      'car': 2,
      'motorcycle': 3,
      'bus': 5,
      'truck': 7
    };
    return classMap[className] || -1;
  }

  getModelInfo(): string {
    if (!this.isLoaded) return 'ANPR ëª¨ë¸ ì—†ìŒ';
    if (this.plateDetector && (this.plateDetector as any).model) {
      return 'YOLOv8 ë²ˆí˜¸íŒ ê°ì§€ ëª¨ë¸ (TensorFlow.js)';
    }
    return 'ì‹¤ì‹œê°„ ë²ˆí˜¸íŒ ê°ì§€ ì‹œìŠ¤í…œ (Computer Vision)';
  }

  dispose(): void {
    if (this.plateDetector) {
      this.plateDetector.dispose();
      this.plateDetector = null;
    }
    this.isLoaded = false;
  }
}

// ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
let globalDetector: ANPRDetector | null = null;

export async function getANPRDetector(onProgress?: (progress: number) => void): Promise<ANPRDetector> {
  if (!globalDetector) {
    globalDetector = new ANPRDetector();
    await globalDetector.loadModel(onProgress);
  }
  return globalDetector;
}